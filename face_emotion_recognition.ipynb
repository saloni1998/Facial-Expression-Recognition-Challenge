{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./fer2013/fer2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'emotion', u'pixels', u'Usage'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array(data['pixels'].iloc[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PrivateTest', 'PublicTest', 'Training'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['Usage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PrivateTest', 3589), ('PublicTest', 3589), ('Training', 28709)]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(data['Usage'], return_counts=True)\n",
    "print(list(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35887"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Usage'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data):\n",
    "    x_train=[]\n",
    "    y_train=[]\n",
    "    x_test=[]\n",
    "    y_test=[]\n",
    "    x_val=[]\n",
    "    y_val=[]\n",
    "    for i in range(len(data)):\n",
    "        a=np.array(data['pixels'].iloc[i].split(\" \"))\n",
    "        a= [float(x) for x in a]\n",
    "        a=np.reshape(a,(48,48,1))\n",
    "        \n",
    "        if(data['Usage'].iloc[i]=='Training'):\n",
    "            x_train.append(a)\n",
    "            y_train.append(data['emotion'].iloc[i])\n",
    "        elif(data['Usage'].iloc[i]=='PublicTest'):\n",
    "            x_val.append(a)\n",
    "            y_val.append(data['emotion'].iloc[i])\n",
    "        elif(data['Usage'].iloc[i]=='PrivateTest'):\n",
    "            x_test.append(a)\n",
    "            y_test.append(data['emotion'].iloc[i])\n",
    "    return np.array(x_train),np.array(y_train),np.array(x_val),np.array(y_val),np.array(x_test),np.array(y_test)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_val,y_val,x_test,y_test=read_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((28709, 48, 48, 1), (3589, 48, 48, 1), (3589, 48, 48, 1))\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,x_val.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe220e0f810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(x_train[1],(48,48)),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input,Dense,Dropout,Conv2D,MaxPooling2D,Flatten,Activation,BatchNormalization,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam,RMSprop,SGD,Nadam,Adagrad\n",
    "from keras.losses import mean_squared_error,binary_crossentropy,categorical_crossentropy\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np_utils.to_categorical(y_train,7)\n",
    "y_test=np_utils.to_categorical(y_test,7)\n",
    "y_val=np_utils.to_categorical(y_val,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    inputs=Input(shape=(48,48,1))\n",
    "    l=inputs\n",
    "    \"\"\"l=Conv2D(filters=16,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=16,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \"\"\"\n",
    "    l=Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \n",
    "    l=Dropout(0.2)(l)\n",
    "    \n",
    "    l=Conv2D(filters=48,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=48,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \n",
    "    l=Dropout(0.25)(l)\n",
    "    \n",
    "    l=Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \n",
    "    l=Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \n",
    "    l=Dropout(0.25)(l)\n",
    "    \n",
    "    l=Conv2D(filters=196,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=Conv2D(filters=196,kernel_size=(3,3),strides=(1,1),padding='same')(l)\n",
    "    l=BatchNormalization()(l)\n",
    "    l=Activation('relu')(l)\n",
    "    l=MaxPooling2D(pool_size=(2,2))(l)\n",
    "    \n",
    "    l=GlobalAveragePooling2D()(l)\n",
    "    l=Dropout(0.4)(l)\n",
    "    l=Dense(196,activation='relu')(l)\n",
    "    l=Dropout(0.5)(l)\n",
    "    l=Dense(128,activation='relu')(l)\n",
    "    l=Dense(7,activation='softmax')(l)\n",
    "    outputs=l\n",
    "    return inputs,outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 48, 48, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 24, 24, 48)        13872     \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 24, 24, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 24, 24, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 24, 24, 48)        20784     \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 24, 24, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 24, 24, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 12, 12, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 3, 3, 196)         225988    \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 3, 3, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 3, 3, 196)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 3, 3, 196)         345940    \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 3, 3, 196)         784       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 3, 3, 196)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 196)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 196)               38612     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               25216     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 970,707\n",
      "Trainable params: 968,835\n",
      "Non-trainable params: 1,872\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs,outputs=make_model()\n",
    "model=Model(inputs=inputs,outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=Adam(0.00005)\n",
    "#optim=SGD(1e-3)\n",
    "loss=categorical_crossentropy\n",
    "model.compile(optim,loss,metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 11s 397us/step - loss: 2.1826 - acc: 0.1800 - val_loss: 1.8539 - val_acc: 0.2494\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 1.9097 - acc: 0.2020 - val_loss: 1.8293 - val_acc: 0.2494\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 1.8662 - acc: 0.2164 - val_loss: 1.8186 - val_acc: 0.2494\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.8398 - acc: 0.2247 - val_loss: 1.8085 - val_acc: 0.2494\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 1.8284 - acc: 0.2305 - val_loss: 1.8050 - val_acc: 0.2494\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.8189 - acc: 0.2355 - val_loss: 1.8040 - val_acc: 0.2494\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.8115 - acc: 0.2356 - val_loss: 1.7986 - val_acc: 0.2494\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.8022 - acc: 0.2432 - val_loss: 1.8049 - val_acc: 0.2491\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.7936 - acc: 0.2508 - val_loss: 1.7978 - val_acc: 0.2494\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 1.7854 - acc: 0.2575 - val_loss: 1.7998 - val_acc: 0.2494\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.7728 - acc: 0.2673 - val_loss: 1.7967 - val_acc: 0.2639\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.7485 - acc: 0.2844 - val_loss: 1.7879 - val_acc: 0.2692\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.7220 - acc: 0.3025 - val_loss: 1.7818 - val_acc: 0.2845\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 1.6950 - acc: 0.3181 - val_loss: 1.7818 - val_acc: 0.3009\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.6763 - acc: 0.3331 - val_loss: 1.7644 - val_acc: 0.3143\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.6457 - acc: 0.3443 - val_loss: 1.7025 - val_acc: 0.3385\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.6228 - acc: 0.3576 - val_loss: 1.7286 - val_acc: 0.3324\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.6075 - acc: 0.3678 - val_loss: 1.6277 - val_acc: 0.3759\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.5831 - acc: 0.3795 - val_loss: 1.6110 - val_acc: 0.3865\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.5671 - acc: 0.3822 - val_loss: 1.5848 - val_acc: 0.3929\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=20,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.5471 - acc: 0.3955 - val_loss: 1.6083 - val_acc: 0.3884\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 1.5323 - acc: 0.4044 - val_loss: 1.5471 - val_acc: 0.4048\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.5146 - acc: 0.4116 - val_loss: 1.4698 - val_acc: 0.4344\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.5033 - acc: 0.4145 - val_loss: 1.4973 - val_acc: 0.4274\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.4860 - acc: 0.4229 - val_loss: 1.4535 - val_acc: 0.4397\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 1.4762 - acc: 0.4280 - val_loss: 1.4299 - val_acc: 0.4539\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.4607 - acc: 0.4342 - val_loss: 1.4240 - val_acc: 0.4508\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.4482 - acc: 0.4374 - val_loss: 1.3966 - val_acc: 0.4631\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 1.4321 - acc: 0.4481 - val_loss: 1.4268 - val_acc: 0.4570\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.4204 - acc: 0.4558 - val_loss: 1.4035 - val_acc: 0.4603\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.4081 - acc: 0.4560 - val_loss: 1.4095 - val_acc: 0.4620\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.3958 - acc: 0.4632 - val_loss: 1.3782 - val_acc: 0.4723\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 1.3926 - acc: 0.4661 - val_loss: 1.3980 - val_acc: 0.4661\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.3812 - acc: 0.4726 - val_loss: 1.3274 - val_acc: 0.4879\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.3643 - acc: 0.4764 - val_loss: 1.3469 - val_acc: 0.4823\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.3585 - acc: 0.4813 - val_loss: 1.3200 - val_acc: 0.4868\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 1.3468 - acc: 0.4823 - val_loss: 1.3048 - val_acc: 0.4987\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.3383 - acc: 0.4886 - val_loss: 1.2982 - val_acc: 0.4987\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 1.3239 - acc: 0.4931 - val_loss: 1.3051 - val_acc: 0.4987\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.3174 - acc: 0.4976 - val_loss: 1.2701 - val_acc: 0.5077\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.3072 - acc: 0.5005 - val_loss: 1.2854 - val_acc: 0.5046\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.2997 - acc: 0.5061 - val_loss: 1.2653 - val_acc: 0.5102\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.2928 - acc: 0.5055 - val_loss: 1.2711 - val_acc: 0.5124\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 1.2844 - acc: 0.5100 - val_loss: 1.2742 - val_acc: 0.5116\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.2694 - acc: 0.5172 - val_loss: 1.2492 - val_acc: 0.5132\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 1.2688 - acc: 0.5160 - val_loss: 1.2517 - val_acc: 0.5216\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 1.2537 - acc: 0.5241 - val_loss: 1.2333 - val_acc: 0.5238\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.2496 - acc: 0.5256 - val_loss: 1.2240 - val_acc: 0.5336\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.2429 - acc: 0.5270 - val_loss: 1.2683 - val_acc: 0.5230\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 1.2326 - acc: 0.5321 - val_loss: 1.2398 - val_acc: 0.5210\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.2260 - acc: 0.5328 - val_loss: 1.2172 - val_acc: 0.5266\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.2174 - acc: 0.5376 - val_loss: 1.2345 - val_acc: 0.5241\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.2091 - acc: 0.5427 - val_loss: 1.1921 - val_acc: 0.5422\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.2003 - acc: 0.5464 - val_loss: 1.2020 - val_acc: 0.5414\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.1969 - acc: 0.5496 - val_loss: 1.1895 - val_acc: 0.5436\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.1851 - acc: 0.5479 - val_loss: 1.1871 - val_acc: 0.5456\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 1.1830 - acc: 0.5571 - val_loss: 1.1977 - val_acc: 0.5458\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.1714 - acc: 0.5581 - val_loss: 1.1786 - val_acc: 0.5553\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 1.1673 - acc: 0.5575 - val_loss: 1.2036 - val_acc: 0.5422\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.1615 - acc: 0.5601 - val_loss: 1.1780 - val_acc: 0.5495\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.1530 - acc: 0.5652 - val_loss: 1.1691 - val_acc: 0.5587\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 1.1416 - acc: 0.5682 - val_loss: 1.1575 - val_acc: 0.5612\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.1388 - acc: 0.5692 - val_loss: 1.1716 - val_acc: 0.5534\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.1313 - acc: 0.5747 - val_loss: 1.1551 - val_acc: 0.5589\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.1267 - acc: 0.5754 - val_loss: 1.1571 - val_acc: 0.5550\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.1197 - acc: 0.5762 - val_loss: 1.1613 - val_acc: 0.5581\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 1.1116 - acc: 0.5777 - val_loss: 1.1374 - val_acc: 0.5612\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.1040 - acc: 0.5821 - val_loss: 1.1603 - val_acc: 0.5570\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.0980 - acc: 0.5884 - val_loss: 1.1457 - val_acc: 0.5667\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 1.0914 - acc: 0.5911 - val_loss: 1.1377 - val_acc: 0.5642\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 8s 289us/step - loss: 1.0842 - acc: 0.5945 - val_loss: 1.1436 - val_acc: 0.5681\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 1.0771 - acc: 0.5975 - val_loss: 1.1456 - val_acc: 0.5670\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 1.0717 - acc: 0.5994 - val_loss: 1.1307 - val_acc: 0.5715\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 1.0668 - acc: 0.5978 - val_loss: 1.1266 - val_acc: 0.5768\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 1.0612 - acc: 0.6001 - val_loss: 1.1571 - val_acc: 0.5648\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 1.0541 - acc: 0.6047 - val_loss: 1.1481 - val_acc: 0.5743\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 8s 295us/step - loss: 1.0517 - acc: 0.6081 - val_loss: 1.1387 - val_acc: 0.5717\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.0431 - acc: 0.6085 - val_loss: 1.1471 - val_acc: 0.5784\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 1.0379 - acc: 0.6117 - val_loss: 1.1325 - val_acc: 0.5795\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 1.0340 - acc: 0.6125 - val_loss: 1.1335 - val_acc: 0.5795\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 1.0287 - acc: 0.6103 - val_loss: 1.1277 - val_acc: 0.5840\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 1.0197 - acc: 0.6173 - val_loss: 1.1367 - val_acc: 0.5798\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 1.0193 - acc: 0.6145 - val_loss: 1.1340 - val_acc: 0.5821\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 1.0096 - acc: 0.6220 - val_loss: 1.1178 - val_acc: 0.5893\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 1.0081 - acc: 0.6231 - val_loss: 1.1125 - val_acc: 0.5935\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9936 - acc: 0.6268 - val_loss: 1.1247 - val_acc: 0.5879\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 0.9936 - acc: 0.6294 - val_loss: 1.1228 - val_acc: 0.5949\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.9856 - acc: 0.6323 - val_loss: 1.1243 - val_acc: 0.5885\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.9820 - acc: 0.6312 - val_loss: 1.1311 - val_acc: 0.5882\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.9752 - acc: 0.6374 - val_loss: 1.1103 - val_acc: 0.5921\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.9735 - acc: 0.6344 - val_loss: 1.1309 - val_acc: 0.5882\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.9689 - acc: 0.6378 - val_loss: 1.1051 - val_acc: 0.5977\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9621 - acc: 0.6388 - val_loss: 1.1181 - val_acc: 0.5963\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9609 - acc: 0.6381 - val_loss: 1.1118 - val_acc: 0.5946\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.9490 - acc: 0.6436 - val_loss: 1.1331 - val_acc: 0.5893\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.9450 - acc: 0.6478 - val_loss: 1.1352 - val_acc: 0.5938\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.9376 - acc: 0.6486 - val_loss: 1.1185 - val_acc: 0.5946\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9394 - acc: 0.6486 - val_loss: 1.1238 - val_acc: 0.5974\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9328 - acc: 0.6484 - val_loss: 1.1156 - val_acc: 0.5954\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.9220 - acc: 0.6551 - val_loss: 1.1441 - val_acc: 0.5949\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.9195 - acc: 0.6548 - val_loss: 1.1228 - val_acc: 0.5965\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.9180 - acc: 0.6581 - val_loss: 1.1192 - val_acc: 0.6041\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9186 - acc: 0.6577 - val_loss: 1.1343 - val_acc: 0.6035\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.9033 - acc: 0.6622 - val_loss: 1.1284 - val_acc: 0.6013\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.8961 - acc: 0.6663 - val_loss: 1.1357 - val_acc: 0.5996\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.8878 - acc: 0.6665 - val_loss: 1.1274 - val_acc: 0.5971\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.8858 - acc: 0.6680 - val_loss: 1.1107 - val_acc: 0.6002\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.8888 - acc: 0.6712 - val_loss: 1.1039 - val_acc: 0.6055\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.8754 - acc: 0.6727 - val_loss: 1.1301 - val_acc: 0.6030\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.8739 - acc: 0.6721 - val_loss: 1.1231 - val_acc: 0.6004\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.8723 - acc: 0.6787 - val_loss: 1.1240 - val_acc: 0.6046\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.8640 - acc: 0.6791 - val_loss: 1.1466 - val_acc: 0.5943\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.8544 - acc: 0.6786 - val_loss: 1.1102 - val_acc: 0.6080\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.8513 - acc: 0.6856 - val_loss: 1.1198 - val_acc: 0.6082\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.8467 - acc: 0.6866 - val_loss: 1.1241 - val_acc: 0.6030\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.8388 - acc: 0.6879 - val_loss: 1.1332 - val_acc: 0.6032\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.8367 - acc: 0.6849 - val_loss: 1.1382 - val_acc: 0.6055\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.8278 - acc: 0.6903 - val_loss: 1.1278 - val_acc: 0.6135\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.8262 - acc: 0.6912 - val_loss: 1.1412 - val_acc: 0.6113\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.8179 - acc: 0.6935 - val_loss: 1.1426 - val_acc: 0.6094\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.8175 - acc: 0.6934 - val_loss: 1.1355 - val_acc: 0.6110\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.8116 - acc: 0.6982 - val_loss: 1.1280 - val_acc: 0.6069\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 0.8053 - acc: 0.7007 - val_loss: 1.1376 - val_acc: 0.6160\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 0.8035 - acc: 0.7004 - val_loss: 1.1679 - val_acc: 0.6074\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 8s 295us/step - loss: 0.8057 - acc: 0.6986 - val_loss: 1.1386 - val_acc: 0.6152\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.7924 - acc: 0.7058 - val_loss: 1.1457 - val_acc: 0.6160\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.7822 - acc: 0.7111 - val_loss: 1.1543 - val_acc: 0.6144\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.7847 - acc: 0.7117 - val_loss: 1.1605 - val_acc: 0.6130\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.7830 - acc: 0.7075 - val_loss: 1.1841 - val_acc: 0.6055\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.7801 - acc: 0.7114 - val_loss: 1.1475 - val_acc: 0.6183\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.7710 - acc: 0.7122 - val_loss: 1.1727 - val_acc: 0.6130\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.7650 - acc: 0.7156 - val_loss: 1.1584 - val_acc: 0.6138\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.7583 - acc: 0.7168 - val_loss: 1.1579 - val_acc: 0.6113\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.7562 - acc: 0.7197 - val_loss: 1.1753 - val_acc: 0.6116\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.7505 - acc: 0.7226 - val_loss: 1.1825 - val_acc: 0.6099\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.7463 - acc: 0.7237 - val_loss: 1.2108 - val_acc: 0.6049\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.7425 - acc: 0.7263 - val_loss: 1.1851 - val_acc: 0.6088\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.7382 - acc: 0.7281 - val_loss: 1.1807 - val_acc: 0.6094\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.7281 - acc: 0.7296 - val_loss: 1.2001 - val_acc: 0.6133\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.7358 - acc: 0.7299 - val_loss: 1.1624 - val_acc: 0.6133\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.7219 - acc: 0.7316 - val_loss: 1.1951 - val_acc: 0.6121\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.7208 - acc: 0.7338 - val_loss: 1.1894 - val_acc: 0.6074\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.7168 - acc: 0.7367 - val_loss: 1.1803 - val_acc: 0.6191\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.7120 - acc: 0.7364 - val_loss: 1.2275 - val_acc: 0.6096\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.7033 - acc: 0.7390 - val_loss: 1.2336 - val_acc: 0.6113\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.7014 - acc: 0.7403 - val_loss: 1.1986 - val_acc: 0.6077\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6974 - acc: 0.7437 - val_loss: 1.2400 - val_acc: 0.6116\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.6949 - acc: 0.7433 - val_loss: 1.2090 - val_acc: 0.6191\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6888 - acc: 0.7433 - val_loss: 1.2169 - val_acc: 0.6174\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.6822 - acc: 0.7494 - val_loss: 1.2513 - val_acc: 0.6191\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.6814 - acc: 0.7474 - val_loss: 1.1986 - val_acc: 0.6177\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.6730 - acc: 0.7486 - val_loss: 1.2299 - val_acc: 0.6147\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.6712 - acc: 0.7519 - val_loss: 1.2042 - val_acc: 0.6147\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.6600 - acc: 0.7560 - val_loss: 1.2374 - val_acc: 0.6163\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.6588 - acc: 0.7561 - val_loss: 1.2313 - val_acc: 0.6186\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.6617 - acc: 0.7567 - val_loss: 1.2445 - val_acc: 0.6186\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.6507 - acc: 0.7611 - val_loss: 1.2273 - val_acc: 0.6180\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.6466 - acc: 0.7611 - val_loss: 1.2493 - val_acc: 0.6172\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6458 - acc: 0.7640 - val_loss: 1.2106 - val_acc: 0.6160\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6405 - acc: 0.7629 - val_loss: 1.2186 - val_acc: 0.6177\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6333 - acc: 0.7679 - val_loss: 1.2590 - val_acc: 0.6233\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6303 - acc: 0.7677 - val_loss: 1.2630 - val_acc: 0.6158\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 309us/step - loss: 0.6325 - acc: 0.7667 - val_loss: 1.2313 - val_acc: 0.6258\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.6353 - acc: 0.7662 - val_loss: 1.2728 - val_acc: 0.6227\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 8s 295us/step - loss: 0.6243 - acc: 0.7708 - val_loss: 1.2427 - val_acc: 0.6202\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.6195 - acc: 0.7723 - val_loss: 1.3056 - val_acc: 0.6169\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.6168 - acc: 0.7717 - val_loss: 1.2629 - val_acc: 0.6188\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.6136 - acc: 0.7717 - val_loss: 1.2759 - val_acc: 0.6205\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.5972 - acc: 0.7815 - val_loss: 1.2870 - val_acc: 0.6197\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.6015 - acc: 0.7801 - val_loss: 1.3140 - val_acc: 0.6127\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/20\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.5980 - acc: 0.7810 - val_loss: 1.2564 - val_acc: 0.6194\n",
      "Epoch 2/20\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.5874 - acc: 0.7829 - val_loss: 1.3261 - val_acc: 0.6244\n",
      "Epoch 3/20\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5885 - acc: 0.7858 - val_loss: 1.2795 - val_acc: 0.6197\n",
      "Epoch 4/20\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 0.5877 - acc: 0.7845 - val_loss: 1.2604 - val_acc: 0.6250\n",
      "Epoch 5/20\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 0.5885 - acc: 0.7851 - val_loss: 1.3156 - val_acc: 0.6222\n",
      "Epoch 6/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5866 - acc: 0.7862 - val_loss: 1.2743 - val_acc: 0.6236\n",
      "Epoch 7/20\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.5657 - acc: 0.7934 - val_loss: 1.2995 - val_acc: 0.6261\n",
      "Epoch 8/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5701 - acc: 0.7925 - val_loss: 1.2908 - val_acc: 0.6202\n",
      "Epoch 9/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5703 - acc: 0.7892 - val_loss: 1.2976 - val_acc: 0.6297\n",
      "Epoch 10/20\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.5601 - acc: 0.7970 - val_loss: 1.3468 - val_acc: 0.6208\n",
      "Epoch 11/20\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.5611 - acc: 0.7956 - val_loss: 1.3249 - val_acc: 0.6183\n",
      "Epoch 12/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5539 - acc: 0.7974 - val_loss: 1.3298 - val_acc: 0.6219\n",
      "Epoch 13/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5496 - acc: 0.7983 - val_loss: 1.3312 - val_acc: 0.6241\n",
      "Epoch 14/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.5476 - acc: 0.7989 - val_loss: 1.3039 - val_acc: 0.6272\n",
      "Epoch 15/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.5453 - acc: 0.8011 - val_loss: 1.3388 - val_acc: 0.6266\n",
      "Epoch 16/20\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.5391 - acc: 0.8037 - val_loss: 1.3356 - val_acc: 0.6258\n",
      "Epoch 17/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5403 - acc: 0.8023 - val_loss: 1.3384 - val_acc: 0.6233\n",
      "Epoch 18/20\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.5326 - acc: 0.8081 - val_loss: 1.3570 - val_acc: 0.6266\n",
      "Epoch 19/20\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.5335 - acc: 0.8057 - val_loss: 1.3247 - val_acc: 0.6239\n",
      "Epoch 20/20\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.5273 - acc: 0.8090 - val_loss: 1.3203 - val_acc: 0.6311\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=20,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.5228 - acc: 0.8111 - val_loss: 1.3206 - val_acc: 0.6236\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.5180 - acc: 0.8117 - val_loss: 1.3291 - val_acc: 0.6255\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 8s 295us/step - loss: 0.5176 - acc: 0.8116 - val_loss: 1.3488 - val_acc: 0.6255\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.5126 - acc: 0.8144 - val_loss: 1.3765 - val_acc: 0.6205\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.5054 - acc: 0.8153 - val_loss: 1.3535 - val_acc: 0.6294\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.5002 - acc: 0.8177 - val_loss: 1.3608 - val_acc: 0.6280\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.5026 - acc: 0.8160 - val_loss: 1.3449 - val_acc: 0.6319\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4968 - acc: 0.8189 - val_loss: 1.3915 - val_acc: 0.6241\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4977 - acc: 0.8193 - val_loss: 1.3558 - val_acc: 0.6280\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.4959 - acc: 0.8182 - val_loss: 1.4039 - val_acc: 0.6264\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4875 - acc: 0.8237 - val_loss: 1.3824 - val_acc: 0.6252\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4854 - acc: 0.8248 - val_loss: 1.4237 - val_acc: 0.6197\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4827 - acc: 0.8258 - val_loss: 1.4214 - val_acc: 0.6241\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4758 - acc: 0.8260 - val_loss: 1.3934 - val_acc: 0.6225\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.4726 - acc: 0.8305 - val_loss: 1.4200 - val_acc: 0.6294\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 307us/step - loss: 0.4675 - acc: 0.8299 - val_loss: 1.3948 - val_acc: 0.6311\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4710 - acc: 0.8293 - val_loss: 1.4315 - val_acc: 0.6227\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.4656 - acc: 0.8299 - val_loss: 1.4568 - val_acc: 0.6239\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4614 - acc: 0.8332 - val_loss: 1.4485 - val_acc: 0.6227\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4521 - acc: 0.8373 - val_loss: 1.4777 - val_acc: 0.6222\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4508 - acc: 0.8372 - val_loss: 1.4952 - val_acc: 0.6300\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4517 - acc: 0.8349 - val_loss: 1.4540 - val_acc: 0.6286\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4448 - acc: 0.8375 - val_loss: 1.4654 - val_acc: 0.6286\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.4408 - acc: 0.8408 - val_loss: 1.4830 - val_acc: 0.6336\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4322 - acc: 0.8424 - val_loss: 1.4881 - val_acc: 0.6219\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4374 - acc: 0.8412 - val_loss: 1.4754 - val_acc: 0.6272\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4463 - acc: 0.8405 - val_loss: 1.4621 - val_acc: 0.6339\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.4234 - acc: 0.8440 - val_loss: 1.4572 - val_acc: 0.6314\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4359 - acc: 0.8442 - val_loss: 1.5308 - val_acc: 0.6202\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.4244 - acc: 0.8467 - val_loss: 1.4581 - val_acc: 0.6350\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4313 - acc: 0.8435 - val_loss: 1.5228 - val_acc: 0.6247\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 309us/step - loss: 0.4174 - acc: 0.8483 - val_loss: 1.4328 - val_acc: 0.6297\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.4153 - acc: 0.8492 - val_loss: 1.5336 - val_acc: 0.6269\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4229 - acc: 0.8476 - val_loss: 1.5048 - val_acc: 0.6283\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4161 - acc: 0.8512 - val_loss: 1.4872 - val_acc: 0.6300\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.4074 - acc: 0.8522 - val_loss: 1.4909 - val_acc: 0.6222\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.4024 - acc: 0.8541 - val_loss: 1.5413 - val_acc: 0.6367\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4058 - acc: 0.8534 - val_loss: 1.5441 - val_acc: 0.6333\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.4030 - acc: 0.8552 - val_loss: 1.5068 - val_acc: 0.6383\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.3977 - acc: 0.8574 - val_loss: 1.5486 - val_acc: 0.6356\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 0.4016 - acc: 0.8558 - val_loss: 1.5274 - val_acc: 0.6311\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.3975 - acc: 0.8559 - val_loss: 1.4986 - val_acc: 0.6317\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3887 - acc: 0.8627 - val_loss: 1.5323 - val_acc: 0.6389\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.3850 - acc: 0.8609 - val_loss: 1.5582 - val_acc: 0.6364\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.3851 - acc: 0.8613 - val_loss: 1.5434 - val_acc: 0.6283\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.3881 - acc: 0.8598 - val_loss: 1.5486 - val_acc: 0.6336\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.3784 - acc: 0.8625 - val_loss: 1.5612 - val_acc: 0.6294\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3746 - acc: 0.8677 - val_loss: 1.6078 - val_acc: 0.6319\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.3737 - acc: 0.8643 - val_loss: 1.5656 - val_acc: 0.6347\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.3709 - acc: 0.8683 - val_loss: 1.6047 - val_acc: 0.6294\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.3717 - acc: 0.8661 - val_loss: 1.5874 - val_acc: 0.6364\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 290us/step - loss: 0.3684 - acc: 0.8702 - val_loss: 1.6408 - val_acc: 0.6261\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 0.3672 - acc: 0.8674 - val_loss: 1.5728 - val_acc: 0.6275\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 8s 295us/step - loss: 0.3650 - acc: 0.8689 - val_loss: 1.5685 - val_acc: 0.6297\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.3645 - acc: 0.8695 - val_loss: 1.5803 - val_acc: 0.6266\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3597 - acc: 0.8721 - val_loss: 1.5687 - val_acc: 0.6275\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3578 - acc: 0.8726 - val_loss: 1.6159 - val_acc: 0.6286\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.3535 - acc: 0.8748 - val_loss: 1.6217 - val_acc: 0.6300\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.3515 - acc: 0.8736 - val_loss: 1.6484 - val_acc: 0.6289\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 313us/step - loss: 0.3541 - acc: 0.8737 - val_loss: 1.6291 - val_acc: 0.6266\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.3442 - acc: 0.8770 - val_loss: 1.5845 - val_acc: 0.6317\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.3457 - acc: 0.8773 - val_loss: 1.6408 - val_acc: 0.6264\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.3408 - acc: 0.8785 - val_loss: 1.6286 - val_acc: 0.6286\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.3355 - acc: 0.8785 - val_loss: 1.6066 - val_acc: 0.6280\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.3417 - acc: 0.8789 - val_loss: 1.6372 - val_acc: 0.6305\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.3316 - acc: 0.8825 - val_loss: 1.6169 - val_acc: 0.6339\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3380 - acc: 0.8799 - val_loss: 1.6393 - val_acc: 0.6278\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.3374 - acc: 0.8775 - val_loss: 1.6332 - val_acc: 0.6367\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.3288 - acc: 0.8831 - val_loss: 1.7138 - val_acc: 0.6236\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.3303 - acc: 0.8797 - val_loss: 1.6294 - val_acc: 0.6342\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3219 - acc: 0.8857 - val_loss: 1.6664 - val_acc: 0.6305\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.3226 - acc: 0.8858 - val_loss: 1.7096 - val_acc: 0.6305\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.3147 - acc: 0.8864 - val_loss: 1.6758 - val_acc: 0.6322\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.3243 - acc: 0.8874 - val_loss: 1.6197 - val_acc: 0.6278\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.3209 - acc: 0.8842 - val_loss: 1.6853 - val_acc: 0.6280\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.3104 - acc: 0.8891 - val_loss: 1.7810 - val_acc: 0.6311\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.3146 - acc: 0.8884 - val_loss: 1.7305 - val_acc: 0.6300\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.3072 - acc: 0.8917 - val_loss: 1.7094 - val_acc: 0.6322\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.3090 - acc: 0.8913 - val_loss: 1.7072 - val_acc: 0.6308\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.3023 - acc: 0.8911 - val_loss: 1.7171 - val_acc: 0.6305\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.3054 - acc: 0.8903 - val_loss: 1.7166 - val_acc: 0.6308\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.2990 - acc: 0.8932 - val_loss: 1.7122 - val_acc: 0.6272\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.2972 - acc: 0.8959 - val_loss: 1.7255 - val_acc: 0.6358\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.3030 - acc: 0.8897 - val_loss: 1.8441 - val_acc: 0.6303\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.2938 - acc: 0.8965 - val_loss: 1.7073 - val_acc: 0.6358\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.2935 - acc: 0.8951 - val_loss: 1.7008 - val_acc: 0.6350\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.2929 - acc: 0.8954 - val_loss: 1.7448 - val_acc: 0.6311\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.2883 - acc: 0.8974 - val_loss: 1.7336 - val_acc: 0.6330\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.2903 - acc: 0.8965 - val_loss: 1.7623 - val_acc: 0.6297\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2899 - acc: 0.8998 - val_loss: 1.7105 - val_acc: 0.6278\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2865 - acc: 0.8993 - val_loss: 1.7326 - val_acc: 0.6291\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2799 - acc: 0.9001 - val_loss: 1.7267 - val_acc: 0.6353\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2867 - acc: 0.8986 - val_loss: 1.7305 - val_acc: 0.6314\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2765 - acc: 0.9040 - val_loss: 1.7702 - val_acc: 0.6319\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 8s 296us/step - loss: 0.2802 - acc: 0.9008 - val_loss: 1.7214 - val_acc: 0.6322\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.2719 - acc: 0.9053 - val_loss: 1.7328 - val_acc: 0.6305\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2715 - acc: 0.9018 - val_loss: 1.7387 - val_acc: 0.6350\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2767 - acc: 0.9012 - val_loss: 1.7606 - val_acc: 0.6383\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.2743 - acc: 0.9034 - val_loss: 1.7936 - val_acc: 0.6342\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 303us/step - loss: 0.2737 - acc: 0.9040 - val_loss: 1.7253 - val_acc: 0.6333\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.2631 - acc: 0.9062 - val_loss: 1.7660 - val_acc: 0.6269\n",
      "Epoch 2/50\n",
      "28709/28709 [==============================] - 8s 291us/step - loss: 0.2657 - acc: 0.9075 - val_loss: 1.8055 - val_acc: 0.6278\n",
      "Epoch 3/50\n",
      "28709/28709 [==============================] - 8s 292us/step - loss: 0.2619 - acc: 0.9076 - val_loss: 1.7644 - val_acc: 0.6289\n",
      "Epoch 4/50\n",
      "28709/28709 [==============================] - 8s 293us/step - loss: 0.2671 - acc: 0.9071 - val_loss: 1.7606 - val_acc: 0.6367\n",
      "Epoch 5/50\n",
      "28709/28709 [==============================] - 8s 294us/step - loss: 0.2573 - acc: 0.9095 - val_loss: 1.8029 - val_acc: 0.6319\n",
      "Epoch 6/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2500 - acc: 0.9123 - val_loss: 1.8660 - val_acc: 0.6339\n",
      "Epoch 7/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2701 - acc: 0.9049 - val_loss: 1.8198 - val_acc: 0.6319\n",
      "Epoch 8/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2519 - acc: 0.9105 - val_loss: 1.7905 - val_acc: 0.6289\n",
      "Epoch 9/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2533 - acc: 0.9130 - val_loss: 1.8315 - val_acc: 0.6311\n",
      "Epoch 10/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2492 - acc: 0.9135 - val_loss: 1.8265 - val_acc: 0.6317\n",
      "Epoch 11/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2478 - acc: 0.9130 - val_loss: 1.8320 - val_acc: 0.6275\n",
      "Epoch 12/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.2454 - acc: 0.9131 - val_loss: 1.7955 - val_acc: 0.6325\n",
      "Epoch 13/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2436 - acc: 0.9167 - val_loss: 1.8894 - val_acc: 0.6347\n",
      "Epoch 14/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2477 - acc: 0.9126 - val_loss: 1.8018 - val_acc: 0.6330\n",
      "Epoch 15/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2459 - acc: 0.9155 - val_loss: 1.8344 - val_acc: 0.6291\n",
      "Epoch 16/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2483 - acc: 0.9130 - val_loss: 1.8113 - val_acc: 0.6342\n",
      "Epoch 17/50\n",
      "28709/28709 [==============================] - 9s 308us/step - loss: 0.2354 - acc: 0.9178 - val_loss: 1.8788 - val_acc: 0.6319\n",
      "Epoch 18/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2352 - acc: 0.9173 - val_loss: 1.8707 - val_acc: 0.6275\n",
      "Epoch 19/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2428 - acc: 0.9158 - val_loss: 1.8577 - val_acc: 0.6264\n",
      "Epoch 20/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2406 - acc: 0.9145 - val_loss: 1.9421 - val_acc: 0.6264\n",
      "Epoch 21/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.2386 - acc: 0.9174 - val_loss: 1.8878 - val_acc: 0.6330\n",
      "Epoch 22/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2378 - acc: 0.9156 - val_loss: 1.8792 - val_acc: 0.6358\n",
      "Epoch 23/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.2323 - acc: 0.9200 - val_loss: 1.8782 - val_acc: 0.6322\n",
      "Epoch 24/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2311 - acc: 0.9181 - val_loss: 1.8238 - val_acc: 0.6375\n",
      "Epoch 25/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.2284 - acc: 0.9207 - val_loss: 1.8869 - val_acc: 0.6319\n",
      "Epoch 26/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2301 - acc: 0.9194 - val_loss: 1.8558 - val_acc: 0.6328\n",
      "Epoch 27/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2358 - acc: 0.9159 - val_loss: 1.8972 - val_acc: 0.6278\n",
      "Epoch 28/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.2318 - acc: 0.9180 - val_loss: 1.8768 - val_acc: 0.6353\n",
      "Epoch 29/50\n",
      "28709/28709 [==============================] - 9s 304us/step - loss: 0.2244 - acc: 0.9231 - val_loss: 1.9023 - val_acc: 0.6291\n",
      "Epoch 30/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.2210 - acc: 0.9216 - val_loss: 1.9713 - val_acc: 0.6289\n",
      "Epoch 31/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.2242 - acc: 0.9228 - val_loss: 1.9708 - val_acc: 0.6347\n",
      "Epoch 32/50\n",
      "28709/28709 [==============================] - 9s 297us/step - loss: 0.2133 - acc: 0.9255 - val_loss: 1.9245 - val_acc: 0.6328\n",
      "Epoch 33/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2193 - acc: 0.9215 - val_loss: 1.9290 - val_acc: 0.6317\n",
      "Epoch 34/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2152 - acc: 0.9233 - val_loss: 1.9064 - val_acc: 0.6367\n",
      "Epoch 35/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.2183 - acc: 0.9225 - val_loss: 1.9273 - val_acc: 0.6280\n",
      "Epoch 36/50\n",
      "28709/28709 [==============================] - 9s 296us/step - loss: 0.2174 - acc: 0.9238 - val_loss: 1.8988 - val_acc: 0.6280\n",
      "Epoch 37/50\n",
      "28709/28709 [==============================] - 9s 305us/step - loss: 0.2180 - acc: 0.9233 - val_loss: 1.9674 - val_acc: 0.6367\n",
      "Epoch 38/50\n",
      "28709/28709 [==============================] - 9s 306us/step - loss: 0.2141 - acc: 0.9245 - val_loss: 1.9099 - val_acc: 0.6333\n",
      "Epoch 39/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2150 - acc: 0.9264 - val_loss: 1.9535 - val_acc: 0.6311\n",
      "Epoch 40/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2069 - acc: 0.9275 - val_loss: 1.9480 - val_acc: 0.6358\n",
      "Epoch 41/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2140 - acc: 0.9269 - val_loss: 1.9121 - val_acc: 0.6397\n",
      "Epoch 42/50\n",
      "28709/28709 [==============================] - 9s 301us/step - loss: 0.2057 - acc: 0.9279 - val_loss: 1.9230 - val_acc: 0.6347\n",
      "Epoch 43/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.2091 - acc: 0.9273 - val_loss: 1.8985 - val_acc: 0.6305\n",
      "Epoch 44/50\n",
      "28709/28709 [==============================] - 9s 310us/step - loss: 0.2072 - acc: 0.9264 - val_loss: 1.9899 - val_acc: 0.6322\n",
      "Epoch 45/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.2052 - acc: 0.9303 - val_loss: 2.0392 - val_acc: 0.6383\n",
      "Epoch 46/50\n",
      "28709/28709 [==============================] - 9s 300us/step - loss: 0.1990 - acc: 0.9312 - val_loss: 1.9861 - val_acc: 0.6339\n",
      "Epoch 47/50\n",
      "28709/28709 [==============================] - 9s 302us/step - loss: 0.1968 - acc: 0.9305 - val_loss: 1.9516 - val_acc: 0.6317\n",
      "Epoch 48/50\n",
      "28709/28709 [==============================] - 9s 299us/step - loss: 0.1972 - acc: 0.9301 - val_loss: 1.9083 - val_acc: 0.6383\n",
      "Epoch 49/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.1993 - acc: 0.9315 - val_loss: 1.9813 - val_acc: 0.6303\n",
      "Epoch 50/50\n",
      "28709/28709 [==============================] - 9s 298us/step - loss: 0.2015 - acc: 0.9306 - val_loss: 1.9934 - val_acc: 0.6353\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=50,batch_size=256,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 1s 186us/step\n",
      "('precision :', 0.6472555029588212)\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.evaluate(x_test,y_test)\n",
    "print(\"precision :\",y_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
